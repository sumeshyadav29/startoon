{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17dc8973",
   "metadata": {},
   "source": [
    "# Coding Section : -\n",
    "\n",
    "### 1. Could we sum it?\n",
    "\n",
    "Let Ankur has given a large weight W, and a list of smaller weights in an array. He needs to write a\n",
    "code in order to find \"can we form weight W or not, using smaller weights\". He only knows dp\n",
    "solution. Could you write a code solution for him without using dp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca9e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_form_weight(W, weight_list):\n",
    "    if W == 0:\n",
    "        return True\n",
    "    if len(weight_list) == 0:\n",
    "        return False\n",
    "    \n",
    "    current_weight = weight_list[0]\n",
    "    remaining_weights = weight_list[1:]\n",
    "    \n",
    "    # Check if we can form the weight W by including the current weight or excluding it\n",
    "    return can_form_weight(W - current_weight, remaining_weights) or can_form_weight(W, remaining_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629415a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=15\n",
    "w= [14,53,75,36,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1814ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(can_form_weight(weight,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf2104a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "weight_1=12\n",
    "w_1=[2,5,6,7]\n",
    "print(can_form_weight(weight_1,w_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bcd85d",
   "metadata": {},
   "source": [
    "# Descriptive Section : -\n",
    "\n",
    "### 1. How Do You Handle Missing or Corrupted Data in a Dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e05753",
   "metadata": {},
   "source": [
    "We begin by identifying missing data in the dataset. Missing data can be represented in various forms, such as null values, NaN (Not a Number), or placeholders like \"N/A\" or \"-9999\", it could even be empty spaces. Understanding the nature and patterns of missing data is crucial for choosing the appropriate handling techniques.\n",
    "\n",
    "If the amount of missing data is relatively small and randomly distributed, we may choose to remove the rows or columns containing missing data. However, this approach should be used cautiously, as removing too much data can lead to loss of information and potential bias in the analysis.\n",
    "\n",
    "For large number of missing data we would use the following methods :\n",
    "\n",
    "##### 1. Imputation :\n",
    "It involves filling in the missing values with estimated or predicted values. Common imputation techniques include mean imputation, median imputation, mode imputation, or regression imputation (using regression models to predict missing values based on other variables).\n",
    "    \n",
    "#####    2. Advanced imputation techniques: \n",
    "In cases where the missing data has a more complex pattern, advanced imputation techniques like multiple imputation or k-nearest neighbors (KNN) imputation can be used. Multiple imputation generates multiple plausible values for each missing data point, taking into account the uncertainty associated with imputed values. KNN imputation replaces missing values with values from similar observations based on their characteristics.\n",
    "    \n",
    "#####    3. Flagging or separate treatment:\n",
    "In some cases, it may be appropriate to flag missing data as a separate category or create a separate variable to indicate the presence of missing values. This can help prevent the loss of valuable information and allow the missingness to be treated as a separate feature in the analysis.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15040848",
   "metadata": {},
   "source": [
    "## 2. What Are the Three Stages of Building a Model in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a8348",
   "metadata": {},
   "source": [
    "The three stages of building a model in machine learning are:\n",
    "\n",
    "### 1. Data Preprocessing:\n",
    "Data preprocessing is the initial stage where the raw data is prepared for the model. It involves several steps:\n",
    "##### A. Data Cleaning: \n",
    "Handling missing values, outliers, and noisy data by either removing them, imputing values, or using other techniques.\n",
    "##### B. Data Transformation: \n",
    "Standardizing or normalizing the data to ensure all features are on a similar scale.\n",
    "##### C. Feature Selection/Engineering: \n",
    "Selecting relevant features or creating new features that are more informative for the model.\n",
    "##### D. Data Splitting: \n",
    "Splitting the dataset into training, validation, and testing sets to evaluate the model's performance.\n",
    "### 2. Model Building and Training:\n",
    "In this stage, a suitable machine learning algorithm is selected, and the model is built and trained on the prepared dataset. The steps involved include:\n",
    "##### A.Selecting an Algorithm: \n",
    "Choosing an appropriate algorithm based on the problem type (e.g., classification, regression, clustering) and the characteristics of the data.\n",
    "##### B. Model Initialization: \n",
    "Initializing the model with appropriate parameters and hyperparameters.\n",
    "##### C. Training the Model: \n",
    "Using the training dataset to optimize the model's parameters by minimizing the chosen objective or loss function.\n",
    "##### D. Model Evaluation: \n",
    "Assessing the model's performance on the validation dataset, using evaluation metrics such as accuracy, precision, recall, or mean squared error.\n",
    "### 3. Model Evaluation and Deployment:\n",
    "The final stage involves evaluating the model's performance and, if satisfactory, deploying it for prediction or inference. This stage includes:\n",
    "##### A. Performance Evaluation: \n",
    "Assessing the model's performance on the testing dataset, which provides an unbiased estimate of its ability to generalize to new, unseen data.\n",
    "##### B. Model Fine-tuning: \n",
    "Adjusting hyperparameters or model architecture based on performance evaluation to optimize the model's performance.\n",
    "##### C. Model Deployment: \n",
    "Integrating the trained model into the production environment or making it available for real-time predictions.\n",
    "##### D. Monitoring and Maintenance: \n",
    "Continuously monitoring the model's performance and retraining or updating it periodically to adapt to changing data patterns or improve its accuracy over time.\n",
    "\n",
    "These three stages of data preprocessing, model building and training, and model evaluation and deployment form a typical pipeline for building a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4853cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
